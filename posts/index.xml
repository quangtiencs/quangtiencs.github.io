<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on quangtiencs</title>
    <link>https://quangtiencs.com/posts/</link>
    <description>Recent content in Posts on quangtiencs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>quangtiencs âž¤ bet on myself &amp; beat the odds</copyright>
    <lastBuildDate>Mon, 23 Jan 2023 08:00:00 +0700</lastBuildDate><atom:link href="https://quangtiencs.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tensorflow.Js &amp; Typescript [4]: Quantile Regression</title>
      <link>https://quangtiencs.com/posts/tensorflowjs_typescript_04/</link>
      <pubDate>Mon, 23 Jan 2023 08:00:00 +0700</pubDate>
      
      <guid>https://quangtiencs.com/posts/tensorflowjs_typescript_04/</guid>
      <description>Quantile Regression: Github: https://github.com/quangtiencs/tensorflowjs_typescript_tutorials/tree/main/004_quantile_regression/webbrowser_tensorflowjs_typescript
import { Tensor, Tensor2D, tensor2d } from &#34;@tensorflow/tfjs&#34;; import embed from &#34;vega-embed&#34;; import * as tf from &#34;@tensorflow/tfjs&#34;; try { // I know. I&#39;m lazy :-D tf.setBackend(&#34;webgl&#34;); } catch (err) { console.log(err); } document.querySelector(&#34;#device&#34;)!!.innerHTML = `Backend by: ${tf.getBackend()}`; function make_synthetic_data(true_w: number, true_b: number) { let x: tf.Tensor1D = tf.randomUniform([500], 0.0, 2.0); let noise = tf.randomNormal([500], 0, 0.8); let y = x.mul(tf.scalar(true_w)).add(tf.scalar(true_b)).add(noise); return { &#34;x&#34;: x, &#34;</description>
    </item>
    
    <item>
      <title>Tensorflow.Js &amp; Typescript [3]: Modeling</title>
      <link>https://quangtiencs.com/posts/tensorflowjs_typescript_03/</link>
      <pubDate>Sun, 22 Jan 2023 20:00:00 +0700</pubDate>
      
      <guid>https://quangtiencs.com/posts/tensorflowjs_typescript_03/</guid>
      <description>Tensorflow.JS provides an application programming interface similar to Tensorflow (Python API). Although it has few choices (layers, models, optimizers), it is still helpful in some applications that need online learning on client devices.
1. APIs: Sometimes useful:
Layers API: tf.layers.dense, tf.layers.dropout, tf.layers.embedding, tf.layers.dense (elu, hardSigmoid, linear, relu, relu6, selu, sigmoid, softmax, softplus, softsign, tanh, swish, mish), Model API: tf.sequential, tf.model. Build-In Optimizers: sgd, adagrad, adadelta, adam, adamax, rmsprop. Build-In Loss functions: tf.</description>
    </item>
    
    <item>
      <title>Tensorflow.Js &amp; Typescript [2]: Memory management</title>
      <link>https://quangtiencs.com/posts/tensorflowjs_typescript_02/</link>
      <pubDate>Sat, 05 Nov 2022 00:00:00 +0530</pubDate>
      
      <guid>https://quangtiencs.com/posts/tensorflowjs_typescript_02/</guid>
      <description>Management Memory is essential for every program to work efficiently. Although Javascript has a Garbage Collector, our programs with TensorflowJS don&amp;rsquo;t get the same automatic memory management.
The tensor objects are persistent with the memory, although the javascript variable has no reference. This lead to memory leak problem.
Let&amp;rsquo;s understand the problem deeper through examples!
1. Memory information: Sometimes you need to get your memory information, and these functions are helpful:</description>
    </item>
    
    <item>
      <title>Tensorflow.Js &amp; Typescript [1]: Quick Start</title>
      <link>https://quangtiencs.com/posts/tensorflowjs_typescript_01/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0530</pubDate>
      
      <guid>https://quangtiencs.com/posts/tensorflowjs_typescript_01/</guid>
      <description>TensorFlow is one of the most well-known libraries for machine learning. The most significant advantage of TensorFlow versus other libraries is designed to simplify the development of cross-platform projects.
These days, TensorFlow.js (Javascript) is a sub-project of Tensorflow that support three environments: Node.js, Web browser, and Mobile (via React Native). Unfortunately, Javascript is not a good programming language for data science projects because it is easy to make mistakes with little experience.</description>
    </item>
    
    <item>
      <title>Julia Language - Euler Project</title>
      <link>https://quangtiencs.com/posts/julia_euler_project/</link>
      <pubDate>Sun, 10 Jul 2022 00:00:00 +0530</pubDate>
      
      <guid>https://quangtiencs.com/posts/julia_euler_project/</guid>
      <description>Github: https://github.com/quangtiencs/julia_project_euler Project Euler 8: Largest product in a series HackerRank: https://www.hackerrank.com/contests/projecteuler/challenges/euler008 Euler: https://projecteuler.net/problem=8 function greatest_product_of_consecutive_digits(array::Array{Int}, k::Int)::Int product = prod(array[1:k]) cache = array[1] maximum_prod = product for i in 1:(length(array)-k) if cache != 0 product = div(product, cache) * array[k+i] else product = prod(array[1+i:k+i]) end cache = array[1+i] if product &amp;gt; maximum_prod maximum_prod = product end end return maximum_prod end function main() t = parse(Int64, readline()) for i in 1:t n, k = map((x) -&amp;gt; parse(Int64, x), split(readline(), &amp;quot; &amp;quot;)) arr_number = [parse(Int, e) for e in readline()] result = greatest_product_of_consecutive_digits(arr_number, k) println(result) end end main() Project Euler 7: 10001st prime HackerRank: https://www.</description>
    </item>
    
    <item>
      <title>Bayesian Multi-Logit Regression implemented in Tensorflow Probability</title>
      <link>https://quangtiencs.com/posts/bayesian_logistics_tensorflow_probability/</link>
      <pubDate>Sun, 20 Feb 2022 00:00:00 +0530</pubDate>
      
      <guid>https://quangtiencs.com/posts/bayesian_logistics_tensorflow_probability/</guid>
      <description>Bayesian Multi-Logit Regression is a probabilistic model for multiclass classification. This tutorial will make a prototype model in Tensorflow Probability and fit it with No-U-Turn Sampler.
Let&amp;rsquo;s start!
1. Model specification: Multi-Logit regression for \(K\) classes has the following form:
$$p(y | x, \beta) = \text{Categorical}(y| \text{softmax}(x \beta))$$
With:
\(x \): input features (row) vector \(x = [x_1,&amp;hellip; x_D] \in R^D \) \(y \): the predicted outcome of the class label \(\beta \): weight matrix for \(K\) classes and \(D\) dimensions The bayesian version of this model with pior:</description>
    </item>
    
  </channel>
</rss>
