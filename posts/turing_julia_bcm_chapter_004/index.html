<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>[playground] Julia Turing.jl : Bayesian Cognitive Modeling - Inferences with gaussians - quangtiencs</title><link rel="icon" type="image/png" href=/icon/quangtiencs_hawk.png /><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="[playground] Julia Turing.jl : Bayesian Cognitive Modeling - Inferences with gaussians" />
<meta property="og:description" content="bayesian cognitive modeling chapter 4 with julia programming language" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://quangtiencs.com/posts/turing_julia_bcm_chapter_004/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-22T08:00:00+07:00" />
<meta property="article:modified_time" content="2023-03-22T08:00:00+07:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[playground] Julia Turing.jl : Bayesian Cognitive Modeling - Inferences with gaussians"/>
<meta name="twitter:description" content="bayesian cognitive modeling chapter 4 with julia programming language"/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://quangtiencs.com/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://quangtiencs.com/css/main.css" />
	<link rel="stylesheet" type="text/css" href="https://quangtiencs.com/css/custom_css.css" />
	

	<script src="https://quangtiencs.com/js/feather.min.js"></script>
	
	<script src="https://quangtiencs.com/js/main.js"></script>
	<script src="https://quangtiencs.com/js/jquery.min.js"></script>
	<script src="https://quangtiencs.com/js/jquery-ui.min.js"></script>
	<script src="https://quangtiencs.com/js/jquery.smartmenus.min.js"></script>
	<script src="https://quangtiencs.com/js/prism.js"></script>

	
	
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-RWDCPM6GZ6"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag() { dataLayer.push(arguments); }
		gtag('js', new Date());

		gtag('config', 'G-RWDCPM6GZ6');
	</script>
	
</head>

<body>
	<div class="container wrapper post">
		<div class="header">
   <div><a href="/"><img style="width: 100%;max-width: 568px;height: auto;" src="/quangtiencs.gif"></a></div>

   <style>
      .iconsvg:hover {
         border-radius: 2px;
         fill: #ff2d55;
         background-color: #ffd60a;
      }
   </style>
   <div style="padding: 5px 5px 5px 5px;" class="flat" align="center">
      <a style="padding: 0px 5px 0px 5px;text-decoration: none;color: #8e8e93" href="https://goodreads.com/quangtiencs"
         target="_blank" rel="noopener">
         <svg width="24" height="24" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter"
            class="iconsvg svg-inline--fa fa-twitter fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg"
            viewBox="0 0 512 512">
            <path class="iconsvg" fill="#8e8e93"
               d="M299.9 191.2c5.1 37.3-4.7 79-35.9 100.7-22.3 15.5-52.8 14.1-70.8 5.7-37.1-17.3-49.5-58.6-46.8-97.2 4.3-60.9 40.9-87.9 75.3-87.5 46.9-.2 71.8 31.8 78.2 78.3zM448 88v336c0 30.9-25.1 56-56 56H56c-30.9 0-56-25.1-56-56V88c0-30.9 25.1-56 56-56h336c30.9 0 56 25.1 56 56zM330 313.2s-.1-34-.1-217.3h-29v40.3c-.8.3-1.2-.5-1.6-1.2-9.6-20.7-35.9-46.3-76-46-51.9.4-87.2 31.2-100.6 77.8-4.3 14.9-5.8 30.1-5.5 45.6 1.7 77.9 45.1 117.8 112.4 115.2 28.9-1.1 54.5-17 69-45.2.5-1 1.1-1.9 1.7-2.9.2.1.4.1.6.2.3 3.8.2 30.7.1 34.5-.2 14.8-2 29.5-7.2 43.5-7.8 21-22.3 34.7-44.5 39.5-17.8 3.9-35.6 3.8-53.2-1.2-21.5-6.1-36.5-19-41.1-41.8-.3-1.6-1.3-1.3-2.3-1.3h-26.8c.8 10.6 3.2 20.3 8.5 29.2 24.2 40.5 82.7 48.5 128.2 37.4 49.9-12.3 67.3-54.9 67.4-106.3z" />
         </svg>
      </a>
      <a style="padding: 0px 5px 0px 5px;text-decoration: none;color: #8e8e93" href="https://twitter.com/quangtiencs"
         target="_blank" rel="noopener">
         <svg width="24" height="24" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter"
            class="iconsvg svg-inline--fa fa-twitter fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg"
            viewBox="0 0 512 512">
            <path class="iconsvg" fill="#8e8e93" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/>
         </svg>
      </a>
      
      <a style="padding: 0px 5px 0px 5px;text-decoration: none;color: #8e8e93" href="https://github.com/quangtiencs"
         target="_blank" rel="noopener">
         <svg width="24" height="24" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github"
            class="iconsvg svg-inline--fa fa-github fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg"
            viewBox="0 0 496 512">
            <path class="iconsvg" fill="#8e8e93"
               d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
            </path>
         </svg>
      </a>
      <a style="padding: 0px 5px 0px 5px;text-decoration: none;color: #8e8e93"
         href="https://www.linkedin.com/in/quangtiencs/" target="_blank" rel="noopener">
         <svg width="24" height="24" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in"
            class="iconsvg svg-inline--fa fa-linkedin-in fa-w-14" role="img" xmlns="http://www.w3.org/2000/svg"
            viewBox="0 0 448 512">
            <path class="iconsvg" fill="#8e8e93"
               d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z">
            </path>
         </svg>
      </a>
      
      <a style="padding: 0px 5px 0px 5px;text-decoration: none;color: #8e8e93" href="/index.xml"
         target="_blank" rel="noopener">
         <svg width="24" height="24" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="telegram-plane"
            class="iconsvg svg-inline--fa fa-telegram-plane fa-w-14" role="img" xmlns="http://www.w3.org/2000/svg"
            viewBox="0 0 448 512">
            <path class="iconsvg" fill="#8e8e93"
               d="M64 32C28.7 32 0 60.7 0 96V416c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V96c0-35.3-28.7-64-64-64H64zM96 136c0-13.3 10.7-24 24-24c137 0 248 111 248 248c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-110.5-89.5-200-200-200c-13.3 0-24-10.7-24-24zm0 96c0-13.3 10.7-24 24-24c83.9 0 152 68.1 152 152c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-57.4-46.6-104-104-104c-13.3 0-24-10.7-24-24zm0 120a32 32 0 1 1 64 0 32 32 0 1 1 -64 0z">
            </path>
         </svg>
      </a>
      <a style="padding: 0px 5px 0px 5px;text-decoration: none;color: #8e8e93" href="https://thetalog.com"
         target="_blank" rel="noopener">
         <svg width="60" height="24" version="1.1" viewBox="0 0 600 240" xmlns="http://www.w3.org/2000/svg">
            <g>
               <path class="iconsvg" fill="#8e8e93"
                  d="m0 120v-119h600v238h-600zm553.42 57.206c3.2995-1.1447 5.9323-2.9705 8-5.5477l3.0819-3.8415 0.28535-36.962 0.28535-36.962-10.571 0.60697-0.61694 7.4364-2.9276-3.3343c-8.1244-9.2532-25.066-6.3897-31.155 5.2656-2.6648 5.1011-2.8004 6.0154-2.8004 18.88 0 15.706 1.0526 20.176 5.9626 25.323 7.4443 7.8033 22.43 7.8865 28.782 0.15986l2.245-2.7307 5e-3 9.1392c7e-3 13.465-0.3368 13.763-16.406 14.214l-12.589 0.35282v9.7944l11.75-0.0438c8.3922-0.0313 13.155-0.53137 16.668-1.75zm-21.652-36.122-3.2658-2.9155-0.32748-12.984c-0.36757-14.574 0.58581-17.974 5.7948-20.668 3.7141-1.9206 10.296-1.9494 13.948-0.061 4.6908 2.4257 6.0852 6.893 6.0852 19.495 0 16.025-2.7971 20.049-13.935 20.049-4.1474 0-5.609-0.51346-8.2997-2.9155zm-324.62 16.755c6.7826-2.0321 14.858-10.624 14.858-15.807 0-0.58332-2.2829-1.0154-5.25-0.9936-4.8061 0.0353-5.4208 0.31006-7.2698 3.25-2.516 4.0004-8.2441 6.1005-14.415 5.2851-8.3765-1.1069-12.065-5.8582-12.065-15.541v-5.0321h39l-0.01-8.75c-8e-3 -7.1407-0.45422-9.7046-2.4264-13.94-8.8218-18.948-40.159-16.883-46.074 3.0354-0.94717 3.1902-1.49 9.2566-1.49 16.655 0 18.512 3.2336 25.872 13.459 30.633 5.6902 2.6497 15.115 3.174 21.682 1.2063zm-24.14-40.589c4e-3 -8.4529 5.5933-14.338 13.678-14.401 9.3579-0.07248 14.321 4.6409 14.321 13.601v4.5497h-28l2e-3 -3.75zm155.78 40.197c2.0448-0.85417 4.9554-2.7384 6.4679-4.1871l2.75-2.634v7.3742h11v-24.532c0-27.759-0.23982-28.949-6.9982-34.734-12.659-10.836-37.743-4.6494-40.615 10.016l-0.63655 3.25h4.9369c4.3199 0 5.2126-0.37291 7.1427-2.9835 3.3898-4.585 7.5765-6.3134 14.002-5.7806 4.6218 0.38327 5.9585 0.96472 8.3364 3.626 2.3798 2.6634 2.832 4.0453 2.832 8.6538v5.4842h-12.532c-13.352 0-17.742 1.0429-22.299 5.2977-3.7906 3.5393-5.1686 7.1925-5.1686 13.702 0 8.8188 3.3237 14.075 11.007 17.407 4.5775 1.985 15.068 2.0062 19.775 0.0399zm-14.425-8.4385c-5.6334-2.2734-7.2873-11.651-2.9459-16.703 2.3586-2.7446 2.6746-2.813 14.5-3.1395l12.089-0.33375v6.4489c0 7.4074-2.0629 11.011-7.6358 13.34-3.6405 1.5211-12.657 1.7392-16.007 0.38724zm157.25 8.5169c5.7566-1.7095 10.905-6.2868 13.526-12.025 2.6761-5.8591 2.6803-33.122 6e-3 -39.009-3.749-8.2524-11.746-12.8-22.635-12.873-10.591-0.07046-18.219 4.206-22.808 12.787-1.9829 3.708-2.1898 5.5611-2.1911 19.621-1e-3 14.69 0.13634 15.794 2.5533 20.491 5.416 10.524 18.18 14.978 31.548 11.008zm-16.288-9.989c-5.6382-2.4522-6.8147-6.2009-6.8147-21.714 0-12.242 0.21671-13.973 2.0645-16.5 5.0813-6.9476 15.348-8.0506 21.749-2.3365l3.1866 2.8447 0.3207 14.997c0.25583 11.964 0.0119 15.595-1.206 17.95-2.8639 5.5381-12.209 7.8422-19.3 4.7582zm-400.31-26.536v-37h23v-10h-57v10h23v74h11zm50.006 15.75c3e-3 -11.688 0.46623-22.909 1.0292-24.936 1.5778-5.6806 5.9887-8.8143 12.407-8.8143 3.9107 0 6.0064 0.56475 8.0444 2.1679 5.0028 3.9352 5.5137 6.7889 5.5137 30.8v22.032h11v-22.818c0-26.872-0.77369-30.937-6.949-36.516-8.7595-7.9137-23.785-7.07-29.091 1.6335l-1.952 3.2014-0.00748-29.5h-11v84h11l6e-3 -21.25zm174.99 16.25v-5h-9.9274c-9.5337 0-10.01-0.1045-12-2.6349-1.9347-2.4596-2.0726-3.923-2.0726-22v-19.365h26.11l-0.60958-9.5-25.5-0.55975v-16.94h-11v17h-17v10h16.858l0.32114 21.25c0.37061 24.524 0.94586 26.516 8.8059 30.5 3.7879 1.92 6.0214 2.25 15.227 2.25h10.788zm143 0v-5h-38v-74h-11v84h49z" />
            </g>
         </svg>
      </a>
   </div>

   
   <nav class="main-nav" role="navigation">

      
      <input id="main-menu-state" type="checkbox" />
      <label class="main-menu-btn" for="main-menu-state">
         <span class="main-menu-btn-icon"></span>
      </label>

      <h2 class="nav-brand"><a>♬ navigator :: </a></h2>

      <ul id="main-menu" class="sm sm-mint">
         <li><a href="/">home</a></li>
         <li><a href="/posts">blog</a></li>
         <li><a>list</a>
            <ul>
               <li><a href="/project">projects</a></li>
               <li><a href="https://goodreads.com/quangtiencs">books</a></li>
            </ul>
         </li>
         <li><a>thought</a>
            <ul>
               <li><a href="/vietnam">vietnam</a></li>
               <li><a href="/english">english</a></li>
            </ul>
         </li>
         <li><a href="/about">about</a></li>
      </ul>
   </nav>
   <script>
      $(function () {
         $('#main-menu').smartmenus({
            mainMenuSubOffsetX: -1,
            subMenusSubOffsetX: 10,
            subMenusSubOffsetY: 0
         });
      });

      
      $(function () {
         var $mainMenuState = $('#main-menu-state');
         if ($mainMenuState.length) {
            
            $mainMenuState.change(function (e) {
               var $menu = $('#main-menu');
               if (this.checked) {
                  $menu.hide().slideDown(250, function () { $menu.css('display', ''); });
               } else {
                  $menu.show().slideUp(250, function () { $menu.css('display', ''); });
               }
            });
            
            $(window).bind('beforeunload unload', function () {
               if ($mainMenuState[0].checked) {
                  $mainMenuState[0].click();
               }
            });
         }
      });</script>
</div>

		<div class="post-header">
			<h1 class="title">[playground] Julia Turing.jl : Bayesian Cognitive Modeling - Inferences with gaussians</h1>
			<div class="meta">Posted at &mdash; Mar 22, 2023</div>
		</div>

		<div class="markdown">
			<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">
<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>
<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<p>Github: <a href="https://github.com/quangtiencs/bayesian-cognitive-modeling-with-turing.jl">https://github.com/quangtiencs/bayesian-cognitive-modeling-with-turing.jl</a></p>
<pre class="line-numbers language-julia"><code>
using DynamicPPL, Turing
using StatsPlots, Random
using LaTeXStrings
using CSV
using DataFrames
using SpecialFunctions
</code></pre>
<pre class="line-numbers language-julia"><code>
format=:png
</code></pre>
<h2 id="41-inferring-a-mean-and-standard-deviation">4.1 Inferring a mean and standard deviation</h2>
<p>$$ \mu \sim \text{Gaussian}(0, \sqrt{1000})  $$
$$ \sigma \sim \text{Uniform} (0, 10)  $$
$$ x_{i} \sim \text{Gaussian} (\mu, \sigma^2)  $$</p>
<pre class="line-numbers language-julia"><code>
x = [1.1, 1.9, 2.3, 1.8]

@model function GaussianModel(x)
    mu ~ Normal(0, sqrt(1000))
    sigma ~ Uniform(0, 10.0)

    for i in eachindex(x)
        x[i] ~ Normal(mu, sigma)
    end
end

iterations=10_000

chain = sample(GaussianModel(x), NUTS(2000, 0.9), iterations, thinning=10)
plot(chain, alpha=0.5, size=(700, 400), fmt=format)
</code></pre>
<p><img src="/images/bcm_julia_turing_004/output_4_1.svg" alt="svg"></p>
<pre class="line-numbers language-julia"><code>
chain
</code></pre>
<pre class="language-shell"><code>
Iterations        = 2001:10:101991
Number of chains  = 1
Samples per chain = 10000
Wall duration     = 6.8 seconds
Compute duration  = 6.8 seconds
parameters        = mu, sigma
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, 
                    hamiltonian_energy, hamiltonian_energy_error, 
                    max_hamiltonian_energy_error, tree_depth, numerical_error, 
                    step_size, nom_step_size

Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

          mu    1.7676    0.6697     0.0067    0.0072   8799.3432    1.0000    ⋯
       sigma    0.9946    0.8889     0.0089    0.0093   8529.8922    1.0000    ⋯
                                                                1 column omitted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5% 
      Symbol   Float64   Float64   Float64   Float64   Float64 

          mu    0.4649    1.5347    1.7764    2.0204    2.9320
       sigma    0.3130    0.5140    0.7272    1.1275    3.4459
</code></pre>
<pre class="line-numbers language-julia"><code>
p = marginalkde(chain[:mu], chain[:sigma], size=(500, 500), fmt=format)
scatter!(p.subplots[2], chain[:mu], chain[:sigma], alpha=0.1, markersize=1)
</code></pre>
<p><img src="/images/bcm_julia_turing_004/output_6_1.svg" alt="svg"></p>
<pre class="line-numbers language-julia"><code>
autocorplot(chain, fmt=format)
</code></pre>
<p><img src="/images/bcm_julia_turing_004/output_7_0.svg" alt="svg"></p>
<h2 id="42-the-seven-scientists">4.2 The seven scientists</h2>
<p>$$ \mu \sim \text{Gaussian}(0, \sqrt{1000})  $$
$$ \lambda_{i} \sim \text{Gamma} (k=.001, \theta = 1 / .001)  $$
$$ \sigma_{i} = 1/{\sqrt\lambda_{i}} $$<br>
$$ x_{i} \sim \text{Gaussian} (\mu, \sigma_{i})  $$</p>
<pre class="line-numbers language-julia"><code>
x = [-27.020, 3.570, 8.191, 9.898, 9.603, 9.945, 10.056]

@model function SvenScientists(x)
    mu ~ Normal(0, sqrt(1000))
    
    # α và θ ó =)) hỏng phải alpha beta haha
    lambda ~ filldist(Gamma(0.01, 1 / 0.01), 7)
    sigma = 1 ./ (sqrt.(lambda))
    
    for i in eachindex(x)
        x[i] ~ Normal(mu, sigma[i])
    end
end

iterations=20_000
burnin=4_000

chain = sample(SvenScientists(x), NUTS(), iterations, burnin=burnin)
plot(chain, alpha=0.5, size=(700, 1500), fmt=format)
</code></pre>
<p><img src="/images/bcm_julia_turing_004/output_9_1.svg" alt="svg"></p>
<pre class="line-numbers language-julia"><code>
chain
</code></pre>
<pre class="language-shell"><code>
Iterations        = 2001:10:101991
Number of chains  = 1
Samples per chain = 10000
Wall duration     = 6.8 seconds
Compute duration  = 6.8 seconds
parameters        = mu, sigma
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, 
                    hamiltonian_energy, hamiltonian_energy_error, 
                    max_hamiltonian_energy_error, tree_depth, numerical_error, 
                    step_size, nom_step_size

Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

          mu    1.7676    0.6697     0.0067    0.0072   8799.3432    1.0000    ⋯
       sigma    0.9946    0.8889     0.0089    0.0093   8529.8922    1.0000    ⋯
                                                                1 column omitted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5% 
      Symbol   Float64   Float64   Float64   Float64   Float64 

          mu    0.4649    1.5347    1.7764    2.0204    2.9320
       sigma    0.3130    0.5140    0.7272    1.1275    3.4459
</code></pre>
<pre class="line-numbers language-julia"><code>
?Turing.Gamma
</code></pre>
<p></code></pre>
Gamma(α,θ)
</code></pre></p>
<p>The <em>Gamma distribution</em> with shape parameter <code>α</code> and scale <code>θ</code> has probability density function</p>
<p>$$
f(x; \alpha, \theta) = \frac{x^{\alpha-1} e^{-x/\theta}}{\Gamma(\alpha) \theta^\alpha},
\quad x &gt; 0
$$</p>
<h2 id="43-repeated-measurement-of-iq">4.3 Repeated measurement of IQ</h2>
<p>$$ \mu_{i} \sim \text{Uniform}(0, 300)  $$
$$ \sigma \sim \text{Uniform} (0, 100)  $$
$$ x_{ij} \sim \text{Gaussian} (\mu_{i}, \sigma)  $$</p>
<pre class="line-numbers language-julia"><code>
x = [[90, 95, 100], [105, 110, 115], [150, 155, 160]]

@model function RepeatedMeasurementIQ(x)
    mu_i ~ filldist(Uniform(0, 300.), 3)
    sigma ~ Uniform(0, 100.)
    
    for i in eachindex(x)
        for j in eachindex(x[i])
            x[i][j] ~ Normal(mu_i[i], sigma)
        end
    end
end

iterations=20_000
burnin=4_000

chain = sample(RepeatedMeasurementIQ(x), NUTS(), iterations, burnin=burnin)
plot(chain, fmt=format, alpha=0.5, size=(700, 800))
</code></pre>
<p><img src="/images/bcm_julia_turing_004/output_13_1.svg" alt="svg"></p>
<pre class="line-numbers language-julia"><code>
density(chain[:"mu_i[1]"], size=(800, 150))
density!(chain[:"mu_i[2]"])
density!(chain[:"mu_i[3]"])
</code></pre>
<p><img src="/images/bcm_julia_turing_004/output_14_0.svg" alt="svg"></p>
<pre class="line-numbers language-julia"><code>
chain
</code></pre>
<pre class="language-shell"><code>
Iterations        = 1001:1:21000
Number of chains  = 1
Samples per chain = 20000
Wall duration     = 2.71 seconds
Compute duration  = 2.71 seconds
parameters        = mu_i[1], mu_i[2], mu_i[3], sigma
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, 
                    hamiltonian_energy, hamiltonian_energy_error, 
                    max_hamiltonian_energy_error, tree_depth, numerical_error, 
                    step_size, nom_step_size

Summary Statistics
  parameters       mean       std   naive_se      mcse          ess      rhat  ⋯
      Symbol    Float64   Float64    Float64   Float64      Float64   Float64  ⋯

     mu_i[1]    95.0648    4.1115     0.0291    0.0309   15506.3153    1.0000  ⋯
     mu_i[2]   109.9797    4.0659     0.0288    0.0317   12564.5068    1.0000  ⋯
     mu_i[3]   155.0112    4.0802     0.0289    0.0344   14992.6288    1.0000  ⋯
       sigma     6.5279    2.6715     0.0189    0.0326    6467.7532    1.0001  ⋯
                                                                1 column omitted

Quantiles
  parameters       2.5%      25.0%      50.0%      75.0%      97.5% 
      Symbol    Float64    Float64    Float64    Float64    Float64 

     mu_i[1]    87.0204    92.7278    95.0066    97.3270   103.3776
     mu_i[2]   101.8947   107.6774   109.9983   112.2714   117.9291
     mu_i[3]   146.7623   152.6509   155.0004   157.3264   163.2994
       sigma     3.4400     4.7723     5.9069     7.5275    13.3027
</code></pre>
		</div>

		<div class="post-tags">
			
				
					<nav class="nav tags">
							<ul class="flat">
								
								<li><a href="/tags/playground">playground</a></li>
								
								<li><a href="/tags/julia">julia</a></li>
								
								<li><a href="/tags/turing">turing</a></li>
								
								<li><a href="/tags/bayesian">bayesian</a></li>
								
							</ul>
					</nav>
				
			
		</div>
		</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> quangtiencs ➤ bet on myself &amp; beat the odds | 
	</nav>
</div><script>feather.replace()</script>
</body>
</html>
